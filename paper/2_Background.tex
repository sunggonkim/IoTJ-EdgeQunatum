\section{Background}

\subsection{Quantum Circuit Simulation on Edge Devices}
Several approaches have been designed to simulate quantum circuits on classical hardware, offering various trade-offs between memory efficiency, execution speed, and fidelity~\cite{qsim, svsim, suzuki2021qulacs, villalonga2019flexible}. 
These simulation methodologies are generally categorized into two types: tensor network contraction and full state vector simulation.

\noindent\textbf{Tensor network simulation.}
Tensor network simulation represents quantum states as a network of interconnected tensors and evaluates the circuit by contracting these tensors. 
This method is highly effective for circuits with limited entanglement or shallow depth, as it avoids storing the entire state vector.
However, its computational cost grows exponentially with the amount of entanglement (entanglement entropy) in the circuit, making it unsuitable for simulating deep, highly entangled quantum algorithms such as Quantum Volume or random circuits on edge devices with limited computational power~\cite{gray2018quimb, lykov2022tensor}.

\noindent\textbf{Full state vector simulation.}
Full state vector simulation explicitly stores and updates the complex amplitudes of all $2^n$ basis states, where $n$ is the number of qubits. 
It provides exact results and complete information about the quantum state, including phase and superposition, which is essential for algorithm verification and error analysis~\cite{guerreschi2020intel, de2007massively}.
As the most general-purpose and accurate approach, our work focuses on full state vector simulation.

Since full state vector simulation maintains the complete system state, it serves as the ground truth for validating quantum hardware and algorithms.
However, it suffers from an exponential growth in memory requirements as the number of qubits increases.
The memory complexity is $\mathcal{O}(2^n)$, with each amplitude requiring 16 bytes (double-precision complex) or 8 bytes (single-precision).
For example, simulating 30 qubits requires 16 GB of memory, which may fit within the unified memory of high-end edge devices like the NVIDIA Jetson AGX Orin.
However, a 34-qubit simulation requires 256 GB, and a 40-qubit simulation demands 16 TB, far exceeding the physical DRAM capacity of any standalone edge system.
Consequently, simulating such large-scale circuits on edge devices necessitates utilizing secondary storage (NVMe SSDs) as an extension of main memory, which introduces significant performance challenges due to the bandwidth disparity between DRAM and storage.
\EdgeQuantum is designed to address these memory constraints by enabling scalable full state vector simulation on resource-constrained edge architectures.

\subsection{Memory Architecture in Edge Computing}

To effectively handle data-intensive applications like quantum simulation on edge devices, it is essential to understand the underlying memory architecture.
Unlike HPC clusters that utilize discrete CPUs and GPUs connected via PCIe, edge devices such as the NVIDIA Jetson series employ a System-on-Chip (SoC) design with a Unified Memory Architecture (UMA)~\cite{nvidia2022jetson}.
In this architecture, the CPU and GPU share a single physical DRAM pool, eliminating the need for data transfers over a PCIe bus.
However, despite this architectural advantage, the total memory capacity remains a hard bottleneck (e.g., 8 GB to 64 GB), restricting the maximum number of qubits that can be simulated in-memory.
When the state vector size exceeds physical DRAM, the system must resort to demand paging or explicit I/O management to swap data between DRAM and storage.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\columnwidth]{Figures/background_edge.pdf}
    \caption{Memory hierarchy and bandwidth disparity in edge computing architectures.}
    \label{fig:edge_memory_hierarchy}
\end{figure}

Figure~\ref{fig:edge_memory_hierarchy} illustrates the memory hierarchy of a typical edge device.
As depicted, the hierarchy consists of three tiers: on-chip caches, unified DRAM, and external NVMe storage.
The unified DRAM offers high bandwidth (e.g., up to 204 GB/s on Jetson Orin) shared between the CPU and GPU.
In contrast, external NVMe storage provides significantly lower bandwidth (e.g., 3-6 GB/s) and higher latency.
Standard simulation frameworks such as \textit{Qsim}~\cite{qsim} and \textit{CuStateVec}~\cite{bayraktar2023cuquantum} rely on the operating system's virtual memory management (OS-native swapping) to handle data larger than physical RAM.
However, this approach suffers from severe performance degradation due to I/O thrashing and the semantic gap between the GPU driver and the OS file system.
Specifically, when a GPU kernel accesses a page not present in physical memory, it triggers a page fault that blocks execution until the OS fetches data from the disk.
Since the OS is unaware of the GPU's memory access patterns, it often makes suboptimal eviction decisions, leading to high latency and low GPU utilization.

To address these problems, recent studies in graph processing and deep learning have proposed out-of-core mechanisms~\cite{lin2022hm, hwang2020centaur} that explicitly manage data movement between storage and GPU memory.
These approaches typically employ a user-space buffer manager to prefetch data and overlap I/O with computation.
However, applying these techniques to quantum simulation on unified memory architectures presents unique challenges.
Existing out-of-core frameworks often assume discrete memory spaces (Host RAM vs. Device VRAM) and rely on explicit \texttt{cudaMemcpy} operations, which are redundant on UMA systems.
Furthermore, generic I/O libraries fail to leverage the specific access patterns of quantum gates, where the stride of memory access grows exponentially with the target qubit index.
This results in inefficient I/O operations and poor cache locality.
Therefore, optimizing quantum simulation on edge devices requires a specialized memory management strategy that exploits the zero-copy capabilities of UMA while efficiently handling the sequential yet strided access patterns inherent to quantum algorithms.
\EdgeQuantum overcomes these limitations by implementing a UVM-aware asynchronous pipeline that integrates efficient I/O scheduling with zero-copy computation, ensuring high performance even when the state vector far exceeds physical memory capacity.