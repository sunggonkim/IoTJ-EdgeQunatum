\section{Related Work}
\label{sec:related}

\subsection{Optimizing Quantum Circuit Simulation}

There have been many studies that optimize quantum circuit simulation to enhance performance on high-end hardware.
Previous studies~\cite{cuquantum, 10.1145/3771577, guerreschi2020intel} focused on utilizing massive parallelism in GPUs and distributed clusters for full state vector simulation.
These approaches accelerate execution and extend scalability by distributing the state vector across aggregated video memory (VRAM) in leadership-class supercomputers.
Other studies~\cite{zhang2021hyquas, xu2024atlas, zhang2022uniq} have proposed static compilation and circuit partitioning techniques to reduce communication overhead.
These methods analyze quantum circuits in advance to generate optimized execution plans or precompiled kernels, aiming to maximize kernel occupancy and minimize inter-node data transfer.
In addition, tensor network-based approaches have been proposed~\cite{gray2018quimb, lykov2022tensor, pan2022simulation} to reduce the memory footprint by decomposing quantum states into interconnected tensors.
These methods provide significant memory savings for shallow or low-entanglement circuits but face exponential complexity growth when simulating deep circuits with high entanglement.

Our study aligns with these prior efforts in improving the computational efficiency of quantum circuit simulation.
However, \EdgeQuantum aims to democratize quantum simulation by targeting resource-constrained edge devices rather than relying on inaccessible HPC infrastructure.
Existing datacenter-centric approaches such as \textit{ScaleQsim} and \textit{cuQuantum} assume abundant memory resources and high-bandwidth interconnects, which leads to execution failures on embedded devices where physical memory is strictly limited.
\EdgeQuantum addresses this limitation by trading execution speed for capacity.
It partitions the state vector across the storage hierarchy and employs a specialized execution pipeline, enabling large-scale simulation on commodity hardware without requiring millions of dollars in infrastructure.

\subsection{Memory Extension and Compression Techniques}

To address the memory scalability bottleneck, several studies have explored alternative memory hierarchies and data representations.
Previous studies~\cite{park2022snuqs, wang2023enabling} extended simulation capacity by offloading state vectors to high-performance SSDs.
These approaches manage the movement of data pages between host memory and storage to support simulations exceeding physical RAM capacity.
Other studies~\cite{zhang2025bmqsim, wu2019full, zhang2024overcoming} have proposed lossless compression and adaptive error-bounded encoding techniques to reduce memory consumption.
These methods dynamically compress state vectors during simulation, allowing systems to store larger quantum states within limited memory footprints.
In the context of edge computing, research has primarily focused on quantum key distribution (QKD) and lightweight post-quantum cryptography (PQC) rather than full circuit simulation.
While frameworks such as PennyLane~\cite{pennylane} support hybrid quantum-classical workflows, they lack specific optimizations for the memory hierarchy of edge devices.

Our study aligns with these prior efforts in utilizing storage offloading and compression to expand simulation capacity.
However, \EdgeQuantum differs by targeting the unique Unified Memory Architecture (UMA) of edge devices.
Previous storage-based approaches such as \textit{SnuQS} rely on CPU-centric memory management which incurs high synchronization overhead, while compression frameworks such as \textit{BMQSim} compete for limited GPU resources on embedded systems.
Through a UVM-aware asynchronous pipeline, \EdgeQuantum integrates storage offloading and LZ4 compression into a unified framework that minimizes CPU-GPU synchronization.
Additionally, it exploits the zero-copy capabilities of edge architectures to overlap data movement with computation.
This allows \EdgeQuantum to achieve a 128$\times$ capacity expansion and support 37-qubit simulations on low-power devices, surpassing the capabilities of prior storage-extended simulators.